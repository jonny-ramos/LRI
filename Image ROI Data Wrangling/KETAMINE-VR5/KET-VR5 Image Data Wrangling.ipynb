{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ketamine VR5 - SINGLE LABELED DATA ONLY\n",
    "#### Jonathan Ramos 1/26/2024\n",
    "\n",
    "I'm glad these data came just as I finished the sleep dep set so some of code is still fresh in my brain. For these data, the format of the csvs is quite different (due to the difference in the way PIPSQUEAK vs POLYGON spit out csvs). Col names are different and some label names need to be changed; in particular, some stain type names are simply called \"hand drawn\" if the user added ROIs that were not detected by the polygon algorithm. This causes probems because all hand drawn ROIs of any stain type are all called \"hand drawn.\" This has been an on going issue with polygon, but we have a work around.\n",
    "\n",
    "In the filename col, all files follow a consistent naming scheme:\n",
    "- *_2.tif : PV\n",
    "- *_3.tif : cFos\n",
    "- *_4.tif : Npas4\n",
    "- *_5.tif : WFA\n",
    "\n",
    "Additionally, since there is no subject ID col, we can construct it from informatively named filenames instead. For this project, filenames follow the following format:\n",
    "\n",
    "*(rat number)*_*(brain region)*_*(bregma)*_*(n)*.tif\n",
    "\n",
    "In this notebook I will wrangle all the data into one spot (data is distributed over ~600 small csvs), clean things up, normalize intensity and count mean cell ns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, Wrangling Data\n",
    "### Loading data, stitching sets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/3h2lpxx14kgb12pp_7pltxnc0000gn/T/ipykernel_52455/1229073174.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_number</th>\n",
       "      <th>roi_id</th>\n",
       "      <th>roi_source</th>\n",
       "      <th>roi_type</th>\n",
       "      <th>CoM_x</th>\n",
       "      <th>CoM_y</th>\n",
       "      <th>pixel_area</th>\n",
       "      <th>background</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>median_intensity</th>\n",
       "      <th>...</th>\n",
       "      <th>feret_angle</th>\n",
       "      <th>feret_min</th>\n",
       "      <th>circularity</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>roundness</th>\n",
       "      <th>solidity</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>filename</th>\n",
       "      <th>analysis_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>000-00000</td>\n",
       "      <td>Parvalbumin</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>120.64</td>\n",
       "      <td>307.06</td>\n",
       "      <td>665.0</td>\n",
       "      <td>285.8023</td>\n",
       "      <td>636.1711</td>\n",
       "      <td>677.3578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>-0.4228</td>\n",
       "      <td>-0.6905</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>Thu Jan 25 15:09:00 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>000-00001</td>\n",
       "      <td>Parvalbumin</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>403.99</td>\n",
       "      <td>379.52</td>\n",
       "      <td>468.0</td>\n",
       "      <td>285.8023</td>\n",
       "      <td>412.1381</td>\n",
       "      <td>395.8835</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>1.1555</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>-0.5155</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>Thu Jan 25 15:09:00 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>000-00002</td>\n",
       "      <td>Parvalbumin</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>363.44</td>\n",
       "      <td>463.29</td>\n",
       "      <td>399.0</td>\n",
       "      <td>285.8023</td>\n",
       "      <td>369.5932</td>\n",
       "      <td>366.851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>1.4266</td>\n",
       "      <td>0.6299</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>-0.1709</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>Thu Jan 25 15:09:00 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>000-00003</td>\n",
       "      <td>Parvalbumin</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>68.43</td>\n",
       "      <td>322.91</td>\n",
       "      <td>550.0</td>\n",
       "      <td>285.8023</td>\n",
       "      <td>518.8725</td>\n",
       "      <td>540.6805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>1.6476</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>-0.4078</td>\n",
       "      <td>-0.4258</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>Thu Jan 25 15:09:00 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>000-00004</td>\n",
       "      <td>Parvalbumin</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>386.72</td>\n",
       "      <td>251.18</td>\n",
       "      <td>524.0</td>\n",
       "      <td>285.8023</td>\n",
       "      <td>832.9809</td>\n",
       "      <td>920.6865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>1.0654</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.9066</td>\n",
       "      <td>-0.6879</td>\n",
       "      <td>-0.6308</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>Thu Jan 25 15:09:00 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>FFF-00073</td>\n",
       "      <td>hand-drawn</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>491.39</td>\n",
       "      <td>60.52</td>\n",
       "      <td>130.0</td>\n",
       "      <td>541.3023</td>\n",
       "      <td>435.1857</td>\n",
       "      <td>415.7151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.1835</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>1.3612</td>\n",
       "      <td>1.5127</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>Mon Jan 22 16:14:32 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>FFF-00074</td>\n",
       "      <td>hand-drawn</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>497.35</td>\n",
       "      <td>15.91</td>\n",
       "      <td>65.0</td>\n",
       "      <td>541.3023</td>\n",
       "      <td>413.2948</td>\n",
       "      <td>392.1778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>1.0617</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>3.3638</td>\n",
       "      <td>15.8851</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>Mon Jan 22 16:14:32 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>FFF-00075</td>\n",
       "      <td>hand-drawn</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>437.04</td>\n",
       "      <td>376.98</td>\n",
       "      <td>130.0</td>\n",
       "      <td>541.3023</td>\n",
       "      <td>493.2017</td>\n",
       "      <td>462.339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.1835</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>1.4819</td>\n",
       "      <td>2.5275</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>Mon Jan 22 16:14:32 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>FFF-00076</td>\n",
       "      <td>hand-drawn</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>472.11</td>\n",
       "      <td>432.2</td>\n",
       "      <td>104.0</td>\n",
       "      <td>541.3023</td>\n",
       "      <td>472.384</td>\n",
       "      <td>433.4397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>1.6255</td>\n",
       "      <td>3.4102</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>Mon Jan 22 16:14:32 PST 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>FFF-00077</td>\n",
       "      <td>hand-drawn</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>352.86</td>\n",
       "      <td>214.76</td>\n",
       "      <td>96.0</td>\n",
       "      <td>541.3023</td>\n",
       "      <td>422.3084</td>\n",
       "      <td>387.4282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>1.8271</td>\n",
       "      <td>3.7074</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>Mon Jan 22 16:14:32 PST 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24613 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_number      roi_id    roi_source roi_type   CoM_x   CoM_y  \\\n",
       "0             1   000-00000   Parvalbumin     OVAL  120.64  307.06   \n",
       "1             2   000-00001   Parvalbumin     OVAL  403.99  379.52   \n",
       "2             3   000-00002   Parvalbumin     OVAL  363.44  463.29   \n",
       "3             4   000-00003   Parvalbumin     OVAL   68.43  322.91   \n",
       "4             5   000-00004   Parvalbumin     OVAL  386.72  251.18   \n",
       "..          ...         ...           ...      ...     ...     ...   \n",
       "73           74   FFF-00073    hand-drawn     OVAL  491.39   60.52   \n",
       "74           75   FFF-00074    hand-drawn     OVAL  497.35   15.91   \n",
       "75           76   FFF-00075    hand-drawn     OVAL  437.04  376.98   \n",
       "76           77   FFF-00076    hand-drawn     OVAL  472.11   432.2   \n",
       "77           78   FFF-00077    hand-drawn     OVAL  352.86  214.76   \n",
       "\n",
       "    pixel_area  background mean_intensity median_intensity  ... feret_angle  \\\n",
       "0        665.0    285.8023       636.1711         677.3578  ...         0.0   \n",
       "1        468.0    285.8023       412.1381         395.8835  ...        90.0   \n",
       "2        399.0    285.8023       369.5932          366.851  ...         0.0   \n",
       "3        550.0    285.8023       518.8725         540.6805  ...         0.0   \n",
       "4        524.0    285.8023       832.9809         920.6865  ...         0.0   \n",
       "..         ...         ...            ...              ...  ...         ...   \n",
       "73       130.0    541.3023       435.1857         415.7151  ...         0.0   \n",
       "74        65.0    541.3023       413.2948         392.1778  ...         0.0   \n",
       "75       130.0    541.3023       493.2017          462.339  ...         0.0   \n",
       "76       104.0    541.3023        472.384         433.4397  ...         0.0   \n",
       "77        96.0    541.3023       422.3084         387.4282  ...         0.0   \n",
       "\n",
       "    feret_min circularity aspect_ratio roundness  solidity skewness  kurtosis  \\\n",
       "0        28.0      0.9387       1.1447    0.8205    0.9419  -0.4228   -0.6905   \n",
       "1        24.0      0.8789       1.1555    0.7613    0.8797   0.4731   -0.5155   \n",
       "2        20.0      0.8698       1.4266    0.6299    0.9027   0.3051   -0.1709   \n",
       "3        22.0      0.8089       1.6476     0.535    0.8814  -0.4078   -0.4258   \n",
       "4        26.0      0.9146       1.0654    0.8539    0.9066  -0.6879   -0.6308   \n",
       "..        ...         ...          ...       ...       ...      ...       ...   \n",
       "73       28.0      0.1835       1.1447    0.1604    0.1841   1.3612    1.5127   \n",
       "74       28.0      0.0918       1.0617    0.0933    0.0921   3.3638   15.8851   \n",
       "75       28.0      0.1835       1.1447    0.1604    0.1841   1.4819    2.5275   \n",
       "76       28.0      0.1468       1.1447    0.1283    0.1473   1.6255    3.4102   \n",
       "77       28.0      0.1355       1.1447    0.1184    0.1360   1.8271    3.7074   \n",
       "\n",
       "                     filename                  analysis_date  \n",
       "0     PE-11-7_PFC_3.9_A_2.tif   Thu Jan 25 15:09:00 PST 2024  \n",
       "1     PE-11-7_PFC_3.9_A_2.tif   Thu Jan 25 15:09:00 PST 2024  \n",
       "2     PE-11-7_PFC_3.9_A_2.tif   Thu Jan 25 15:09:00 PST 2024  \n",
       "3     PE-11-7_PFC_3.9_A_2.tif   Thu Jan 25 15:09:00 PST 2024  \n",
       "4     PE-11-7_PFC_3.9_A_2.tif   Thu Jan 25 15:09:00 PST 2024  \n",
       "..                        ...                            ...  \n",
       "73   KET-10-4_PFC_3.5_C_4.tif   Mon Jan 22 16:14:32 PST 2024  \n",
       "74   KET-10-4_PFC_3.5_C_4.tif   Mon Jan 22 16:14:32 PST 2024  \n",
       "75   KET-10-4_PFC_3.5_C_4.tif   Mon Jan 22 16:14:32 PST 2024  \n",
       "76   KET-10-4_PFC_3.5_C_4.tif   Mon Jan 22 16:14:32 PST 2024  \n",
       "77   KET-10-4_PFC_3.5_C_4.tif   Mon Jan 22 16:14:32 PST 2024  \n",
       "\n",
       "[24613 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# load cohort key (there's a few empty rows at the end)\n",
    "df_key = pd.read_csv('KETAMINE_COHORT KEY.csv').dropna()\n",
    "\n",
    "# load data; getting it all in one spot\n",
    "df_full = pd.concat([pd.read_csv(f) for f in glob.glob('CSV_FILES/*/*.csv')])\n",
    "\n",
    "# col names begin with a whitespace char; let's remove all ' ' chars from col names\n",
    "df_full.columns = [col.replace(' ', '') for col in df_full.columns]\n",
    "\n",
    "# let's take a look\n",
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabeling incorrect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were some issues with the naming/cohort key \n",
    "\n",
    "# PE-12-7 was incorrectly labeled as PE-12-3; this was confirmed by JR and AG by checking slide books/hard copies of behavior data\n",
    "df_full['filename'] = df_full.filename.replace({'PE-12-3': 'PE-12-7'}, regex=True)\n",
    "\n",
    "# similarly KET-8-2 was incorrectly labeled as KET-8-5; this was confirmed by JR and AG  by checking slide books. this wouldn't really \n",
    "# change anything since they received the same treatment but let's just change it to the correct label anyway\n",
    "df_full['filename'] = df_full.filename.replace({'KET-8-5': 'KET-8-2'}, regex=True)\n",
    "\n",
    "# check result\n",
    "assert df_full.filename.str.contains('PE-12-3').sum() == 0\n",
    "assert df_full.filename.str.contains('PE-12-7').sum() != 0\n",
    "assert df_full.filename.str.contains('KET-8-5').sum() == 0\n",
    "assert df_full.filename.str.contains('KET-8-2').sum() != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the necessary cols\n",
    "In particular we will need a rat_n (sid) col, stain_type col, and a treatment col. the filename col functions as the image name (iid) col.\n",
    "\n",
    "We need the following cols\n",
    "- rat_n (sid)\n",
    "- treatment\n",
    "- filename (fid)\n",
    "- imagename (iid)\n",
    "- stain_type\n",
    "- CoM_x\n",
    "- CoM_y\n",
    "- mean-background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat_n</th>\n",
       "      <th>treatment</th>\n",
       "      <th>stain_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>image_name</th>\n",
       "      <th>CoM_x</th>\n",
       "      <th>CoM_y</th>\n",
       "      <th>mean-background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PE-11-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>PV</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>PE-11-7_PFC_3.9_A</td>\n",
       "      <td>120.64</td>\n",
       "      <td>307.06</td>\n",
       "      <td>354.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PE-11-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>PV</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>PE-11-7_PFC_3.9_A</td>\n",
       "      <td>403.99</td>\n",
       "      <td>379.52</td>\n",
       "      <td>127.1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PE-11-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>PV</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>PE-11-7_PFC_3.9_A</td>\n",
       "      <td>363.44</td>\n",
       "      <td>463.29</td>\n",
       "      <td>86.6384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PE-11-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>PV</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>PE-11-7_PFC_3.9_A</td>\n",
       "      <td>68.43</td>\n",
       "      <td>322.91</td>\n",
       "      <td>233.9562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PE-11-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>PV</td>\n",
       "      <td>PE-11-7_PFC_3.9_A_2.tif</td>\n",
       "      <td>PE-11-7_PFC_3.9_A</td>\n",
       "      <td>386.72</td>\n",
       "      <td>251.18</td>\n",
       "      <td>547.2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>KET-10-4</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>Npas4</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>KET-10-4_PFC_3.5_C</td>\n",
       "      <td>491.39</td>\n",
       "      <td>60.52</td>\n",
       "      <td>-106.9829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>KET-10-4</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>Npas4</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>KET-10-4_PFC_3.5_C</td>\n",
       "      <td>497.35</td>\n",
       "      <td>15.91</td>\n",
       "      <td>-120.9047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>KET-10-4</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>Npas4</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>KET-10-4_PFC_3.5_C</td>\n",
       "      <td>437.04</td>\n",
       "      <td>376.98</td>\n",
       "      <td>-49.6622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>KET-10-4</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>Npas4</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>KET-10-4_PFC_3.5_C</td>\n",
       "      <td>472.11</td>\n",
       "      <td>432.2</td>\n",
       "      <td>-67.7978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>KET-10-4</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>Npas4</td>\n",
       "      <td>KET-10-4_PFC_3.5_C_4.tif</td>\n",
       "      <td>KET-10-4_PFC_3.5_C</td>\n",
       "      <td>352.86</td>\n",
       "      <td>214.76</td>\n",
       "      <td>-119.9755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24613 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rat_n treatment stain_type                   filename  \\\n",
       "0    PE-11-7   VR5_KET         PV    PE-11-7_PFC_3.9_A_2.tif   \n",
       "1    PE-11-7   VR5_KET         PV    PE-11-7_PFC_3.9_A_2.tif   \n",
       "2    PE-11-7   VR5_KET         PV    PE-11-7_PFC_3.9_A_2.tif   \n",
       "3    PE-11-7   VR5_KET         PV    PE-11-7_PFC_3.9_A_2.tif   \n",
       "4    PE-11-7   VR5_KET         PV    PE-11-7_PFC_3.9_A_2.tif   \n",
       "..       ...       ...        ...                        ...   \n",
       "73  KET-10-4   VR5_SAL      Npas4   KET-10-4_PFC_3.5_C_4.tif   \n",
       "74  KET-10-4   VR5_SAL      Npas4   KET-10-4_PFC_3.5_C_4.tif   \n",
       "75  KET-10-4   VR5_SAL      Npas4   KET-10-4_PFC_3.5_C_4.tif   \n",
       "76  KET-10-4   VR5_SAL      Npas4   KET-10-4_PFC_3.5_C_4.tif   \n",
       "77  KET-10-4   VR5_SAL      Npas4   KET-10-4_PFC_3.5_C_4.tif   \n",
       "\n",
       "             image_name   CoM_x   CoM_y mean-background  \n",
       "0     PE-11-7_PFC_3.9_A  120.64  307.06         354.873  \n",
       "1     PE-11-7_PFC_3.9_A  403.99  379.52        127.1692  \n",
       "2     PE-11-7_PFC_3.9_A  363.44  463.29         86.6384  \n",
       "3     PE-11-7_PFC_3.9_A   68.43  322.91        233.9562  \n",
       "4     PE-11-7_PFC_3.9_A  386.72  251.18        547.2813  \n",
       "..                  ...     ...     ...             ...  \n",
       "73   KET-10-4_PFC_3.5_C  491.39   60.52       -106.9829  \n",
       "74   KET-10-4_PFC_3.5_C  497.35   15.91       -120.9047  \n",
       "75   KET-10-4_PFC_3.5_C  437.04  376.98        -49.6622  \n",
       "76   KET-10-4_PFC_3.5_C  472.11   432.2        -67.7978  \n",
       "77   KET-10-4_PFC_3.5_C  352.86  214.76       -119.9755  \n",
       "\n",
       "[24613 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new rat_n col\n",
    "df_full['rat_n'] = df_full.filename.apply(lambda x: x.split('_')[0])\\\n",
    "    .replace({' ': ''}, regex=True) # for some reason, we have more leading whitespace chars\n",
    "\n",
    "# some checks. we want be sure that the structure of all our rat_n labels is consistent\n",
    "# in particular, we expect something of the form 'PE-12-7', that is we have exactly\n",
    "# two dashes '-' separating some letters, followed by two numbers\n",
    "assert df_full.rat_n.apply(lambda x: len(x.split('-')) == 3).sum() == len(df_full)\n",
    "assert df_full.rat_n.apply(lambda x: x.split('-')[0].isalpha()).sum() == len(df_full)\n",
    "assert df_full.rat_n.apply(lambda x: x.split('-')[1].isnumeric()).sum() == len(df_full)\n",
    "assert df_full.rat_n.apply(lambda x: x.split('-')[2].isnumeric()).sum() == len(df_full)\n",
    "\n",
    "# building a cohort key dictionary from df_key\n",
    "treatment = dict(zip(df_key.Subject, df_key.TX.replace({' ': '_'}, regex=True)))\n",
    "\n",
    "# creating new treatment col by mapping from cohort key dict\n",
    "df_full['treatment'] = df_full.rat_n.map(treatment)\n",
    "\n",
    "# creating new stain_type col from filename\n",
    "stains = {\n",
    "    '.*_2.tif$' : 'PV',\n",
    "    '.*_3.tif$' : 'cFos',\n",
    "    '.*_4.tif$' : 'Npas4',\n",
    "    '.*_5.tif$' : 'WFA'\n",
    "}\n",
    "df_full['stain_type'] = df_full.filename.replace(stains, regex=True)\n",
    "\n",
    "# check that stain_type col contains the appropriate labels\n",
    "assert set(df_full.stain_type.unique()) == set(stains.values())\n",
    "\n",
    "# building image name (iid) from file name (fid) col\n",
    "df_full['image_name'] = df_full.filename.replace({'_[0-9]\\.tif': ''}, regex=True)\n",
    "\n",
    "df_subset = df_full[['rat_n', 'treatment', 'stain_type', 'filename', 'image_name', 'CoM_x', 'CoM_y', 'mean-background']]\n",
    "\n",
    "# let's take a look\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping nans, duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan per col:\n",
      "rat_n              0\n",
      "treatment          0\n",
      "stain_type         0\n",
      "filename           0\n",
      "image_name         0\n",
      "CoM_x              0\n",
      "CoM_y              0\n",
      "mean-background    0\n",
      "dtype: int64\n",
      "\n",
      "Total n of duplicated rows:\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# which cols have nans, how many?\n",
    "print('Nan per col:')\n",
    "print(df_subset.isna().sum())\n",
    "# it looks like we have no nans! nothing to drop here.\n",
    "\n",
    "# how many duplicated rows do we have?\n",
    "print('\\nTotal n of duplicated rows:')\n",
    "print(df_subset.duplicated().sum())\n",
    "\n",
    "# it looks like we have 15 duplicated rows. let's take a look \n",
    "df_full[df_subset.duplicated()].head(15)\n",
    "\n",
    "# I'm not concerned about dropping these duplicates, so let's just toss em\n",
    "df_cleaned = df_subset[~df_subset.duplicated()]\n",
    "assert df_cleaned.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Intensity\n",
    "all parameterized functions will get set aside into module for future use and standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(df, norm_condition):\n",
    "    '''\n",
    "    computes the mean of rows of the norm_condition and divides mean-background by this mean,\n",
    "    normalizing all data to the mean of the norm_condition. sets normalized value into new\n",
    "    column called \"norm mean-background\" and returns new dataframe containing normalized intensity.\n",
    "    '''\n",
    "    df_norm = df[df.treatment == norm_condition]\n",
    "    norm_mean = df_norm['mean-background'].astype('f').mean()\n",
    "\n",
    "    df_norm = df.copy(deep=True)\n",
    "    df_norm['norm mean-background'] = df['mean-background'].astype('f') / norm_mean\n",
    "\n",
    "    # quickly check that the mean of the norm condition is set to about 1.00000\n",
    "    # this is never exatly 1 due to small rounding errors from floating point operations\n",
    "    assert round(df_norm[df_norm.treatment == norm_condition]['norm mean-background'].mean(), 5) == 1\n",
    "    \n",
    "    return df_norm\n",
    "\n",
    "def prism_reorg(df, group):\n",
    "    '''\n",
    "    Takes just the norm_mean-background intensity col per rat, groups by treatment\n",
    "    and \n",
    "    '''\n",
    "    treatments = np.unique(df.treatment)\n",
    "    reorg = []\n",
    "\n",
    "    for t in treatments:\n",
    "        df_treat = df[df.treatment == t]\n",
    "        norm_int_ratn = []\n",
    "        treatment_ratns = np.unique(df_treat.rat_n)\n",
    "\n",
    "        for rat in treatment_ratns:\n",
    "            norm_int = df_treat[df_treat.rat_n == rat]['norm mean-background']\n",
    "            df_normint = pd.DataFrame({t: norm_int}).reset_index(drop=True)\n",
    "            norm_int_ratn.append(df_normint)\n",
    "\n",
    "        # concat \"vertically\"\n",
    "        df_ratn_cols = pd.concat(norm_int_ratn, axis=0).reset_index(drop=True)\n",
    "\n",
    "        # write csv to disk\n",
    "        reorg.append(df_ratn_cols)\n",
    "    \n",
    "    # concat \"horizontally\"\n",
    "    df_prism_reorg = pd.concat(reorg, axis=1)\n",
    "\n",
    "    \n",
    "    # write csv to disk\n",
    "    df_prism_reorg.to_csv(f'{group}_{np.unique(df.stain_type).item()}_{t}_PRISM.csv')\n",
    "\n",
    "    return df_prism_reorg\n",
    "\n",
    "def prism_reorg(df, group):\n",
    "    '''\n",
    "    Takes just the norm_mean-background intensity col per rat, groups by treatment\n",
    "    and \n",
    "    '''\n",
    "    treatments = np.unique(df.treatment)\n",
    "    reorg = []\n",
    "\n",
    "    for t in treatments:\n",
    "        df_treat = df[df.treatment == t]\n",
    "        norm_int_ratn = []\n",
    "        treatment_ratns = np.unique(df_treat.rat_n)\n",
    "\n",
    "        for rat in treatment_ratns:\n",
    "            norm_int = df_treat[df_treat.rat_n == rat]['norm mean-background']\n",
    "            df_normint = pd.DataFrame({t: norm_int}).reset_index(drop=True)\n",
    "            norm_int_ratn.append(df_normint)\n",
    "\n",
    "        # concat \"vertically\"\n",
    "        df_ratn_cols = pd.concat(norm_int_ratn, axis=0).reset_index(drop=True)\n",
    "\n",
    "        # write csv to disk\n",
    "        reorg.append(df_ratn_cols)\n",
    "    \n",
    "    # concat \"horizontally\"\n",
    "    df_prism_reorg = pd.concat(reorg, axis=1)\n",
    "\n",
    "    return df_prism_reorg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Mean Cell Ns\n",
    "Again, all parameterized functions will get set aside into module for future use and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_imgs(df, sid, iid):\n",
    "    '''\n",
    "    takes a dataframe and counts the number of unique strings that occur in the \n",
    "    \"image_name\" col for each rat in \"rat_n\" col\n",
    "    args:\n",
    "        df: pd.core.frame.DataFrame(n, m) \n",
    "            n: the number of rows, \n",
    "            m: the number of features\n",
    "        sid: str, denoting the name of the col containing unique subject ids\n",
    "        iid: str, denoting the name of the col containing unique image ids\n",
    "    return:\n",
    "        df_imgn: pd.core.frame.DataFrame(n=|sid|), m=2)\n",
    "            n: the number of rows, equal to the cardinality of the sid set\n",
    "            (the number of unique ID strings in sid)\n",
    "            this df contains 2 cols: a sid col, and an iid col containing counts\n",
    "    '''\n",
    "    assert iid in df.columns\n",
    "\n",
    "    df_imgn = df.groupby([sid])[[sid, iid]]\\\n",
    "        .apply(lambda x: len(np.unique(x[iid])))\\\n",
    "        .reset_index(name='image_n')\n",
    "    \n",
    "    return df_imgn\n",
    "\n",
    "def count_cells(df, cols):\n",
    "    '''\n",
    "    takes a df and counts the number of instances each distinct row \n",
    "    (created by unique combinations of labels from columns indicated\n",
    "    by cols arg); counts are reported in a new col called \"cell_counts\"\n",
    "    args:\n",
    "        df: pd.core.frame.DataFrame(N, M); N: the number of rows, M: the\n",
    "            number of cols (assumed to have already been split by stain_type)\n",
    "        cols: list(n), n: the number of cols over which to count distinct rows\n",
    "    return:\n",
    "        df_counts: pd.core.frame.DataFrame(N,M+1)\n",
    "    '''\n",
    "    df_counts = df.value_counts(cols)\\\n",
    "        .reset_index(name='cell_counts')\\\n",
    "        .sort_values(by=cols)\n",
    "    \n",
    "    return df_counts\n",
    "\n",
    "def sum_cells(df, cols, iid):\n",
    "    '''\n",
    "    takes cell count df, groups by cols denoted in cols list and computes sum\n",
    "    of cell_counts col for each group. Adds new column \"cell_count_sums\"\n",
    "    containing sums.\n",
    "    args:\n",
    "        df: pd.core.frame.DataFrame(N, M), N: the number of rows (N=|id_col|),\n",
    "            M: the number of cols, must contain col called \"cell_counts\"\n",
    "        cols: list(M-2), list containing col name strings that define each group \n",
    "            for group by and reduction (in this case summing)\n",
    "        iid: str, denotes \n",
    "    return:\n",
    "        df_sums: pd.core.frame.DataFrame; dataframe containing summed cell\n",
    "            counts per subject id.\n",
    "    '''\n",
    "    # remove image id col (we want to sum counts across all images per rat)\n",
    "    reduce_cols = list(filter(lambda x: x != iid, cols))\n",
    "\n",
    "    if 'scaled_counts' in df.columns:\n",
    "            # group by, reduce \n",
    "        df_sums = df.groupby(by=reduce_cols)[cols]\\\n",
    "            .apply(lambda x: np.sum(x.scaled_counts))\\\n",
    "            .reset_index(name='cell_count_sums')\n",
    "    \n",
    "    else:\n",
    "        # group by, reduce \n",
    "        df_sums = df.groupby(by=reduce_cols)[df.columns]\\\n",
    "            .apply(lambda x: np.sum(x.cell_counts))\\\n",
    "            .reset_index(name='cell_count_sums')\n",
    "    \n",
    "    return df_sums\n",
    "\n",
    "def average_counts(df_sums, df_ns, cols, sid, iid):\n",
    "    '''\n",
    "    takes df of cell count sums and df of image ns, and computes the mean cell \n",
    "    n (divides cell count sums by the number of images) for each subject.\n",
    "    args:\n",
    "        df_sums: pd.core.frame.DataFrame(ni, mi), ni: the number of rows\n",
    "            (ni=|sid|), mi: the number of cols (mi = |cols|); must \n",
    "            contain a col \"cell_count_sums\". \n",
    "        df_ns: pd.core.frame.DataFrame(nj, mj), nj: the number of rows \n",
    "            (nj=|sid|), mj: the number of cols (mj=2); must contain a col\n",
    "            \"image_n\" \n",
    "        cols: list(n), n: the number of cols (contains all cols necessary to \n",
    "            create every unique group combination)\n",
    "        sid: str, denoting the name of the col containing unique subject ids\n",
    "        iid: str, denoting the name of the col containing unique image ids\n",
    "    return:\n",
    "        mean_cell_ns: pd.core.frame.DataFrame(N,M), N: the number of rows (N=\n",
    "        |sid|), M: the number of cols (M=|cols|+2)\n",
    "        \n",
    "    '''\n",
    "    # list of cols with out image id, since it was removed during the reduction step\n",
    "    reduce_cols = list(filter(lambda x: x != iid, cols))\n",
    "\n",
    "    # compute mean cell n\n",
    "    mean_cell_ns = df_sums.join(df_ns.set_index(sid), on=sid, how='inner')\\\n",
    "        .sort_values(by=reduce_cols)\n",
    "    mean_cell_ns['mean_cell_n'] = mean_cell_ns.cell_count_sums / mean_cell_ns.image_n\n",
    "\n",
    "    # reorder so that subject id is the first col\n",
    "    col_reorder = [sid] + list(filter(lambda x: x != sid, list(mean_cell_ns.columns)))\n",
    "    mean_cell_ns = mean_cell_ns[col_reorder]\n",
    "\n",
    "    return mean_cell_ns\n",
    "\n",
    "def mean_cell_n(df_stain, df_full, cols, sid, iid, return_counts=False):\n",
    "    '''\n",
    "    wrapper function to compute mean cell ns; magnification/zoom factor \n",
    "    is assuemd to be equal across all images. NOTE that we count total image\n",
    "    ns based on full cleaned dataset: it may be the case the not every image\n",
    "    contains every stain type combination, and we must still count images\n",
    "    with 0 cells of a particular stain type towards the total number of images.\n",
    "    args:\n",
    "        df_stain: pd.core.frame.DataFrame; df containing data for a given stain type\n",
    "        df_full: pd.core.frame.DataFrame; df containing data for full (cleaned) set\n",
    "        cols: list, contains str denoting col names for grouping\n",
    "        sid: str, col name denoting col containing unique subject ids\n",
    "        iid: str, col name denoting col containing unique image ids\n",
    "        return_counts: bool, flag for added utility during debugging\n",
    "    return:\n",
    "        mean_cell_ns: pd.core.frame.DataFrame; df containing final mean cell ns\n",
    "        cell_counts: pd.core.frame. DataFram; df containing cell counts per\n",
    "            image (for debugging)\n",
    "        \n",
    "    '''\n",
    "    # count n of unique image names per subject\n",
    "    img_ns = count_imgs(df_full, sid, iid)\n",
    "\n",
    "    # count n of cells per image for each subject\n",
    "    cell_counts = count_cells(df_stain, cols)\n",
    "\n",
    "    # sum cell counts across all images for each subject\n",
    "    cell_sums = sum_cells(cell_counts, cols, iid)\n",
    "\n",
    "    # compute mean cell count per image for each subject\n",
    "    mean_cell_ns = average_counts(cell_sums, img_ns, cols, sid, iid)\n",
    "\n",
    "    if not return_counts:\n",
    "        return mean_cell_ns\n",
    "    \n",
    "    return (cell_counts, mean_cell_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to run it!\n",
    "#### Normalize Intensity, write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FR1_KET</th>\n",
       "      <th>FR1_SAL</th>\n",
       "      <th>VR5_KET</th>\n",
       "      <th>VR5_SAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.573138</td>\n",
       "      <td>5.740431</td>\n",
       "      <td>-1.730680</td>\n",
       "      <td>-0.584066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.228130</td>\n",
       "      <td>0.071669</td>\n",
       "      <td>-1.073475</td>\n",
       "      <td>-0.080524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373468</td>\n",
       "      <td>0.019555</td>\n",
       "      <td>-0.500109</td>\n",
       "      <td>-0.956723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.247351</td>\n",
       "      <td>3.060095</td>\n",
       "      <td>1.072946</td>\n",
       "      <td>-0.567922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126912</td>\n",
       "      <td>3.312895</td>\n",
       "      <td>-1.526467</td>\n",
       "      <td>-0.273813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.250855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.339845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.134914</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.498651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FR1_KET   FR1_SAL   VR5_KET   VR5_SAL\n",
       "0    3.573138  5.740431 -1.730680 -0.584066\n",
       "1   -0.228130  0.071669 -1.073475 -0.080524\n",
       "2    0.373468  0.019555 -0.500109 -0.956723\n",
       "3   -1.247351  3.060095  1.072946 -0.567922\n",
       "4    0.126912  3.312895 -1.526467 -0.273813\n",
       "..        ...       ...       ...       ...\n",
       "354       NaN       NaN -1.250855       NaN\n",
       "355       NaN       NaN  1.005051       NaN\n",
       "356       NaN       NaN -1.339845       NaN\n",
       "357       NaN       NaN -1.134914       NaN\n",
       "358       NaN       NaN -0.498651       NaN\n",
       "\n",
       "[359 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp = 'VR5_KET'\n",
    "for stain in df_subset.stain_type.unique():\n",
    "\n",
    "    # split by stain\n",
    "    df_stain = df_subset[df_subset.stain_type == stain]\n",
    "\n",
    "    # normalize to FR1_SAL\n",
    "    df_norm = normalize_intensity(df_stain, norm_condition='FR1_SAL')\n",
    "    df_norm.to_csv(f'{grp}_{stain}_single_NORM.csv')\n",
    "\n",
    "    # reorganize into cols for prism\n",
    "    df_prism = prism_reorg(df_norm, grp)\n",
    "    df_prism.to_csv(f'{grp}_{stain}_PRISM.csv')\n",
    "\n",
    "# let's take a look at one of our final output dataframes, organized for entry into prism\n",
    "print(stain)\n",
    "df_prism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count mean cell ns, write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat_n</th>\n",
       "      <th>treatment</th>\n",
       "      <th>stain_type</th>\n",
       "      <th>cell_count_sums</th>\n",
       "      <th>image_n</th>\n",
       "      <th>mean_cell_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KET-10-12</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KET-9-1</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PE-11-1</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PE-11-2</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PE-11-3</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PE-12-1</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PE-12-2</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PE-12-7</td>\n",
       "      <td>FR1_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>9.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KET-10-1</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KET-10-5</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KET-8-2</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KET-9-2</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KET-9-4</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KET-9-5</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KET-9-6</td>\n",
       "      <td>FR1_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KET-10-14</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KET-8-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PE-11-4</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PE-11-5</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PE-11-6</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PE-11-7</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PE-13-2</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PE-13-3</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PE-13-6</td>\n",
       "      <td>VR5_KET</td>\n",
       "      <td>WFA</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KET-10-2</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KET-10-3</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KET-10-4</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PE-13-1</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PE-13-11</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PE-13-9</td>\n",
       "      <td>VR5_SAL</td>\n",
       "      <td>WFA</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rat_n treatment stain_type  cell_count_sums  image_n  mean_cell_n\n",
       "0   KET-10-12   FR1_KET        WFA               32        5         6.40\n",
       "1     KET-9-1   FR1_KET        WFA               29        4         7.25\n",
       "2     PE-11-1   FR1_KET        WFA               20        5         4.00\n",
       "3     PE-11-2   FR1_KET        WFA               25        5         5.00\n",
       "4     PE-11-3   FR1_KET        WFA               46        5         9.20\n",
       "5     PE-12-1   FR1_KET        WFA               26        5         5.20\n",
       "6     PE-12-2   FR1_KET        WFA               39        5         7.80\n",
       "7     PE-12-7   FR1_KET        WFA               47        5         9.40\n",
       "8    KET-10-1   FR1_SAL        WFA               35        5         7.00\n",
       "9    KET-10-5   FR1_SAL        WFA               32        5         6.40\n",
       "10    KET-8-2   FR1_SAL        WFA               33        5         6.60\n",
       "11    KET-9-2   FR1_SAL        WFA               48        5         9.60\n",
       "12    KET-9-4   FR1_SAL        WFA               46        5         9.20\n",
       "13    KET-9-5   FR1_SAL        WFA               45        5         9.00\n",
       "14    KET-9-6   FR1_SAL        WFA               40        5         8.00\n",
       "15  KET-10-14   VR5_KET        WFA               38        5         7.60\n",
       "16    KET-8-7   VR5_KET        WFA               32        4         8.00\n",
       "17    PE-11-4   VR5_KET        WFA               35        5         7.00\n",
       "18    PE-11-5   VR5_KET        WFA               30        5         6.00\n",
       "19    PE-11-6   VR5_KET        WFA               52        5        10.40\n",
       "20    PE-11-7   VR5_KET        WFA               38        5         7.60\n",
       "21    PE-13-2   VR5_KET        WFA               39        5         7.80\n",
       "22    PE-13-3   VR5_KET        WFA               40        5         8.00\n",
       "23    PE-13-6   VR5_KET        WFA               55        5        11.00\n",
       "24   KET-10-2   VR5_SAL        WFA               31        5         6.20\n",
       "25   KET-10-3   VR5_SAL        WFA               35        5         7.00\n",
       "26   KET-10-4   VR5_SAL        WFA               26        5         5.20\n",
       "27    PE-13-1   VR5_SAL        WFA               66        5        13.20\n",
       "28   PE-13-11   VR5_SAL        WFA               52        5        10.40\n",
       "29    PE-13-9   VR5_SAL        WFA               48        5         9.60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count n of unique image names per subject\n",
    "sid = 'rat_n'\n",
    "iid = 'image_name'\n",
    "cols = ['treatment', 'stain_type', sid, iid]\n",
    "\n",
    "# wrapper fn calls\n",
    "for stain in df_cleaned.stain_type.unique():\n",
    "    \n",
    "    # split by stain type\n",
    "    df_stain = df_cleaned[df_cleaned.stain_type == stain]\n",
    "\n",
    "    # compute mean cell ns\n",
    "    df_means = mean_cell_n(df_stain, df_cleaned, cols, sid, iid)\n",
    "\n",
    "    # write to disk\n",
    "    df_means.to_csv(f'{grp}_{stain}_mean_cell_ns.csv')\n",
    "\n",
    "# let's take a look at one of our final output dataframes\n",
    "print(stain)\n",
    "df_means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Intensity?\n",
    "I noticed that in the test output of the normalized intensities reshaped for prism, we were getting some negative values for normalized intensity. Negative values don't really make sense here. This would mean that the observed effect of the treatment results in cells actually being **dimmer** than background. \n",
    "\n",
    "The only way for negative numbers to arise here is if the mean intensity before background subtraction was **less than** the background at the time the image was captured. If the average signal in a selected region was less than (or not different from) background, that is its signal to noise ratio (SNR) is less than 1, it is unclear to me why we would consider this selection as an ROI. \n",
    "\n",
    "This means that either, selections were made where cells actually showed less fluorescence than background (did the stain work?), or background regions were poorly selected (did the background selection include ROIs?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of dim selections across stain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of cells where mean intensity < background, per stain:\n",
      "stain_type\n",
      "Npas4    11324\n",
      "cFos      4828\n",
      "WFA        644\n",
      "PV         466\n",
      "Name: count, dtype: int64\n",
      "\n",
      "percent of cells where mean intensity < background, per stain:\n",
      "stain_type\n",
      "Npas4    91.736876\n",
      "PV       27.622999\n",
      "WFA      55.517241\n",
      "cFos     51.241775\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_full = df_full[~df_full.duplicated()]\n",
    "df_full['mean_intensity'] = df_full.mean_intensity.astype('f')\n",
    "\n",
    "df_lt = df_full.query('mean_intensity < background')\n",
    "\n",
    "print('total number of cells where mean intensity < background, per stain:')\n",
    "print(df_lt.stain_type.value_counts())\n",
    "\n",
    "print('\\npercent of cells where mean intensity < background, per stain:')\n",
    "print(df_lt.stain_type.value_counts() / df_full.stain_type.value_counts() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of dim selections across rats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "percent cells where mean intensity < background, per rat:\n",
      "rat_n\n",
      "KET-10-1     65.707434\n",
      "KET-10-12    68.518519\n",
      "KET-10-14    63.389831\n",
      "KET-10-2     53.207547\n",
      "KET-10-3     60.782443\n",
      "KET-10-4     68.148148\n",
      "KET-10-5     63.955638\n",
      "KET-8-2      62.178218\n",
      "KET-8-7      69.841270\n",
      "KET-9-1      72.389791\n",
      "KET-9-2      74.835526\n",
      "KET-9-4      81.145251\n",
      "KET-9-5      69.240506\n",
      "KET-9-6      59.211823\n",
      "PE-11-1      70.720000\n",
      "PE-11-2      75.552050\n",
      "PE-11-3      75.396825\n",
      "PE-11-4      71.587302\n",
      "PE-11-5      82.324841\n",
      "PE-11-6      79.788839\n",
      "PE-11-7      81.153305\n",
      "PE-12-1      69.776119\n",
      "PE-12-2      71.132765\n",
      "PE-12-7      68.951194\n",
      "PE-13-1      80.444965\n",
      "PE-13-11     66.795367\n",
      "PE-13-2      71.444824\n",
      "PE-13-3      79.567308\n",
      "PE-13-6      79.648241\n",
      "PE-13-9      78.071334\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\npercent cells where mean intensity < background, per rat:')\n",
    "print(df_lt.rat_n.value_counts() / df_full.rat_n.value_counts() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
