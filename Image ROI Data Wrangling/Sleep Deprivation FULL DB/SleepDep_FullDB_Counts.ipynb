{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep Dep full db, CELL COUNT DATA ONLY\n",
    "##### Jonathan Ramos 1/23/2024\n",
    "It looks like I can just get rid of the majority of these uninformative cols at the right end of the set. I will only take the following:\n",
    "- subject_number\n",
    "- image_name\n",
    "- stain_type\n",
    "- xm\n",
    "- ym\n",
    "- ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction\n",
    "- cohort\n",
    "- ZT\n",
    "- treatment\n",
    "- sex\n",
    "- magnification_factor\n",
    "\n",
    "Since I do not yet know the intensity normalization scheme, I will only handle cell count data per stain type combination for now. \n",
    "\n",
    "1/24/2024:\n",
    "completed pipeline, added magnification factor flag in wrapper function to handle rescaling counts across images of unequal magnification/zoom factors. (all images scaled to highest level of magnification to prioritize cutting out data rather than extrapolating) -JR\n",
    "\n",
    "1/25/2024:\n",
    "added \"xm\" and \"ym\" columns to identify duplicate rows. checked for duplciate values; dropped 918 duplicate rows before counting mean cell ns -JR\n",
    "\n",
    "in total, 249 rows with missing data were dropped, 918 duplicated rows were dropped, resulting in a final cleaned dataframe with 881727 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data, dropping nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/3h2lpxx14kgb12pp_7pltxnc0000gn/T/ipykernel_41792/2348598091.py:5: DtypeWarning: Columns (22,25,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fulldb = pd.read_csv('FullDB_ROIsPhenotypesValidated.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_number', 'image_name', 'stain_type', 'cell_number',\n",
      "       'area_minus_background_micronsquared',\n",
      "       'ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction',\n",
      "       'mean_intensity_beforebackgroundsubtraction', 'ROI_intensity_stdev',\n",
      "       'ROI_minimum_intensity', 'ROI_maximum_intensity',\n",
      "       'ROI_intensity_normalizedtoZT0_percohort_perstain',\n",
      "       'magnification_factor', 'xm', 'ym', 'image_background_intensity',\n",
      "       'cohort', 'ZT', 'location_wrt_bregma', 'treatment', 'sex',\n",
      "       'exact_sac_time', 'weight_at_sac', 'analysisdate',\n",
      "       'magnification_adjusted_area', 'which_stain', 'phenotypeGlobal',\n",
      "       'phenotypeOxo', 'phenotypePV', 'phenotypeWFA', 'Is_Duplicate',\n",
      "       'redundant_duplicate', 'confirmed_single', 'confirmed_double',\n",
      "       'confirmed_triple', 'confirmed_AMBIGUOUS', 'unique_Cell_id',\n",
      "       'empiricalPhenotype', 'Proximal_Coordinates', 'Valid_StainType',\n",
      "       'sumConfirmed', 'real_stain_type', 'phenotypeWfa', 'valid_phenotype'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_number</th>\n",
       "      <th>image_name</th>\n",
       "      <th>stain_type</th>\n",
       "      <th>xm</th>\n",
       "      <th>ym</th>\n",
       "      <th>ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction</th>\n",
       "      <th>cohort</th>\n",
       "      <th>ZT</th>\n",
       "      <th>treatment</th>\n",
       "      <th>sex</th>\n",
       "      <th>magnification_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>202.8106</td>\n",
       "      <td>420.7033</td>\n",
       "      <td>15.4825</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>Triple-labeled_8-oxo-dG</td>\n",
       "      <td>303.1551</td>\n",
       "      <td>252.7436</td>\n",
       "      <td>48.1643</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>Double-labeled_8-oxo_co-occurring_with_WFA</td>\n",
       "      <td>303.1551</td>\n",
       "      <td>252.7436</td>\n",
       "      <td>48.1643</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>303.1551</td>\n",
       "      <td>252.7436</td>\n",
       "      <td>48.1643</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>Double-labeled_8-oxo_co-occurring_with_WFA</td>\n",
       "      <td>406.0875</td>\n",
       "      <td>203.2267</td>\n",
       "      <td>29.5644</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_number    image_name                                  stain_type  \\\n",
       "137          RF001  RF001_2.52_L                                    8-oxo-dG   \n",
       "138          RF001  RF001_2.52_L                     Triple-labeled_8-oxo-dG   \n",
       "139          RF001  RF001_2.52_L  Double-labeled_8-oxo_co-occurring_with_WFA   \n",
       "140          RF001  RF001_2.52_L                                    8-oxo-dG   \n",
       "141          RF001  RF001_2.52_L  Double-labeled_8-oxo_co-occurring_with_WFA   \n",
       "\n",
       "           xm        ym  \\\n",
       "137  202.8106  420.7033   \n",
       "138  303.1551  252.7436   \n",
       "139  303.1551  252.7436   \n",
       "140  303.1551  252.7436   \n",
       "141  406.0875  203.2267   \n",
       "\n",
       "     ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction  cohort  ZT  \\\n",
       "137                                            15.4825               3.1  18   \n",
       "138                                            48.1643               3.1  18   \n",
       "139                                            48.1643               3.1  18   \n",
       "140                                            48.1643               3.1  18   \n",
       "141                                            29.5644               3.1  18   \n",
       "\n",
       "    treatment sex  magnification_factor  \n",
       "137        SD   F                 1.633  \n",
       "138        SD   F                 1.633  \n",
       "139        SD   F                 1.633  \n",
       "140        SD   F                 1.633  \n",
       "141        SD   F                 1.633  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df_fulldb = pd.read_csv('FullDB_ROIsPhenotypesValidated.csv')\n",
    "\n",
    "# check cols\n",
    "print(df_fulldb.columns)\n",
    "\n",
    "# pull out cols that we need\n",
    "df_subset = df_fulldb[['subject_number', 'image_name', 'stain_type', 'xm', 'ym', 'ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction', 'cohort', 'ZT', 'treatment', 'sex', 'magnification_factor']]\n",
    "\n",
    "# check for nans\n",
    "df_subset.count() - len(df_subset)\n",
    "\n",
    "# it looks like the mean_intensity col is missing 249 values. let's just remove those rows for now.\n",
    "df_dropna = df_subset[~df_subset.ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction.isna()]\n",
    "\n",
    "# let's take a look\n",
    "df_dropna.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicated rows: 918\n",
      "number of duplicate rows removed: 918\n",
      "\n",
      "duplicates by stain:\n",
      "8-oxo-dG: 794\n",
      "Double-labeled_8-oxo_co-occurring_with_PV: 23\n",
      "Double-labeled_8-oxo_co-occurring_with_WFA: 9\n",
      "Double-labeled_PV_co-occurring_with_8-oxo: 16\n",
      "Double-labeled_PV_co-occurring_with_WFA: 1\n",
      "Double-labeled_WFA_co-occurring_with_8-oxo: 11\n",
      "Double-labeled_WFA_co-occurring_with_PV: 3\n",
      "Parvalbumin: 13\n",
      "Triple-labeled_8-oxo-dG: 2\n",
      "Triple-labeled_WFA: 1\n",
      "WFA: 45\n",
      "\n",
      "checking duplicates by visual inspection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_number</th>\n",
       "      <th>image_name</th>\n",
       "      <th>stain_type</th>\n",
       "      <th>xm</th>\n",
       "      <th>ym</th>\n",
       "      <th>ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction</th>\n",
       "      <th>cohort</th>\n",
       "      <th>ZT</th>\n",
       "      <th>treatment</th>\n",
       "      <th>sex</th>\n",
       "      <th>magnification_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>380.4925</td>\n",
       "      <td>36.4539</td>\n",
       "      <td>37.5291</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>RF001</td>\n",
       "      <td>RF001_2.52_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>380.4925</td>\n",
       "      <td>36.4539</td>\n",
       "      <td>37.5291</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18</td>\n",
       "      <td>SD</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159602</th>\n",
       "      <td>RF045</td>\n",
       "      <td>RF045_2.52_R</td>\n",
       "      <td>Double-labeled_8-oxo_co-occurring_with_PV</td>\n",
       "      <td>164.2470</td>\n",
       "      <td>70.0550</td>\n",
       "      <td>738.5410</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6</td>\n",
       "      <td>TOD_Control</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159603</th>\n",
       "      <td>RF045</td>\n",
       "      <td>RF045_2.52_R</td>\n",
       "      <td>Double-labeled_8-oxo_co-occurring_with_PV</td>\n",
       "      <td>164.2470</td>\n",
       "      <td>70.0550</td>\n",
       "      <td>738.5410</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6</td>\n",
       "      <td>TOD_Control</td>\n",
       "      <td>F</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451563</th>\n",
       "      <td>RM055</td>\n",
       "      <td>RM055_4.2_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>343.7260</td>\n",
       "      <td>170.5280</td>\n",
       "      <td>1043.8400</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15</td>\n",
       "      <td>TOD_Control</td>\n",
       "      <td>M</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451564</th>\n",
       "      <td>RM055</td>\n",
       "      <td>RM055_4.2_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>343.7260</td>\n",
       "      <td>170.5280</td>\n",
       "      <td>1043.8400</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15</td>\n",
       "      <td>TOD_Control</td>\n",
       "      <td>M</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592435</th>\n",
       "      <td>RM086</td>\n",
       "      <td>RM086_4.2_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>32.4160</td>\n",
       "      <td>77.7760</td>\n",
       "      <td>595.3390</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "      <td>TOD_Control</td>\n",
       "      <td>M</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592436</th>\n",
       "      <td>RM086</td>\n",
       "      <td>RM086_4.2_L</td>\n",
       "      <td>8-oxo-dG</td>\n",
       "      <td>32.4160</td>\n",
       "      <td>77.7760</td>\n",
       "      <td>595.3390</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "      <td>TOD_Control</td>\n",
       "      <td>M</td>\n",
       "      <td>1.633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_number    image_name  \\\n",
       "205             RF001  RF001_2.52_L   \n",
       "206             RF001  RF001_2.52_L   \n",
       "159602          RF045  RF045_2.52_R   \n",
       "159603          RF045  RF045_2.52_R   \n",
       "451563          RM055   RM055_4.2_L   \n",
       "451564          RM055   RM055_4.2_L   \n",
       "592435          RM086   RM086_4.2_L   \n",
       "592436          RM086   RM086_4.2_L   \n",
       "\n",
       "                                       stain_type        xm        ym  \\\n",
       "205                                      8-oxo-dG  380.4925   36.4539   \n",
       "206                                      8-oxo-dG  380.4925   36.4539   \n",
       "159602  Double-labeled_8-oxo_co-occurring_with_PV  164.2470   70.0550   \n",
       "159603  Double-labeled_8-oxo_co-occurring_with_PV  164.2470   70.0550   \n",
       "451563                                   8-oxo-dG  343.7260  170.5280   \n",
       "451564                                   8-oxo-dG  343.7260  170.5280   \n",
       "592435                                   8-oxo-dG   32.4160   77.7760   \n",
       "592436                                   8-oxo-dG   32.4160   77.7760   \n",
       "\n",
       "        ROI_mean_intensity_from_PIPSQUEAK_withbackgroundsubtraction  cohort  \\\n",
       "205                                               37.5291               3.1   \n",
       "206                                               37.5291               3.1   \n",
       "159602                                           738.5410               1.2   \n",
       "159603                                           738.5410               1.2   \n",
       "451563                                          1043.8400               3.2   \n",
       "451564                                          1043.8400               3.2   \n",
       "592435                                           595.3390               4.2   \n",
       "592436                                           595.3390               4.2   \n",
       "\n",
       "        ZT    treatment sex  magnification_factor  \n",
       "205     18           SD   F                 1.633  \n",
       "206     18           SD   F                 1.633  \n",
       "159602   6  TOD_Control   F                 1.633  \n",
       "159603   6  TOD_Control   F                 1.633  \n",
       "451563  15  TOD_Control   M                 1.633  \n",
       "451564  15  TOD_Control   M                 1.633  \n",
       "592435   3  TOD_Control   M                 1.633  \n",
       "592436   3  TOD_Control   M                 1.633  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "print(f'number of duplicated rows: {df_dropna.duplicated().sum()}')\n",
    "\n",
    "# drop duplicate rows\n",
    "df_clean = df_dropna[~df_dropna.duplicated()]\n",
    "print(f'number of duplicate rows removed: {len(df_dropna) - len(df_clean)}')\n",
    "\n",
    "# investigating duplicates\n",
    "print('\\nduplicates by stain:')\n",
    "df_duplicated = df_dropna[df_dropna.duplicated()]\n",
    "stains, counts = np.unique((df_duplicated.stain_type), return_counts=True)\n",
    "\n",
    "# it looks like most duplicates occur in rows with stain_type == 8-oxo-dG \n",
    "for key, val in dict(zip(stains, counts)).items():\n",
    "    print(f'{key}: {val}')\n",
    "\n",
    "# if these rows were really duplicated i would expect this resulting \n",
    "# dataframe to have a total of 8 rows, containing exactly 4 unique rows\n",
    "print('\\nchecking duplicates by visual inspection:')\n",
    "pd.concat([\n",
    "    df_dropna.query(f'xm == {df_duplicated.xm.iloc[0]} and\\\n",
    "                      ym == {df_duplicated.ym.iloc[0]} and\\\n",
    "                      stain_type == \"{df_duplicated.stain_type.iloc[0]}\"'),\n",
    "\n",
    "    df_dropna.query(f'xm == {df_duplicated.xm.iloc[123]} and\\\n",
    "                      ym == {df_duplicated.ym.iloc[123]} and\\\n",
    "                      stain_type == \"{df_duplicated.stain_type.iloc[123]}\"'),\n",
    "\n",
    "    df_dropna.query(f'xm == {df_duplicated.xm.iloc[456]} and\\\n",
    "                      ym == {df_duplicated.ym.iloc[456]} and\\\n",
    "                      stain_type == \"{df_duplicated.stain_type.iloc[456]}\"'),\n",
    "\n",
    "    df_dropna.query(f'xm == {df_duplicated.xm.iloc[789]} and\\\n",
    "                      ym == {df_duplicated.ym.iloc[789]} and\\\n",
    "                      stain_type == \"{df_duplicated.stain_type.iloc[789]}\"')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting mean cell ns per subject\n",
    "These parameterized functions will go into a separate module for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_imgs(df, sid_col, iid_col):\n",
    "    '''\n",
    "    takes a dataframe and counts the number of unique strings that occur in the \n",
    "    \"image_name\" col for each rat in \"rat_n\" col\n",
    "    args:\n",
    "        df: pd.core.frame.DataFrame(n, m) \n",
    "            n: the number of rows, \n",
    "            m: the number of features\n",
    "        sid_col: str, denoting the name of the col containing unique subject ids\n",
    "        iid_col: str, denoting the name of the col containing unique image ids\n",
    "    return:\n",
    "        df_imgn: pd.core.frame.DataFrame(n=|sid_col|), m=2)\n",
    "            n: the number of rows, equal to the cardinality of the sid_col set\n",
    "            (the number of unique ID strings in sid_col)\n",
    "            this df contains 2 cols: a sid col, and an iid col containing counts\n",
    "    '''\n",
    "    assert iid_col in df.columns\n",
    "\n",
    "    df_imgn = df.groupby([sid_col])\\\n",
    "        .apply(lambda x: len(np.unique(x.image_name)))\\\n",
    "        .reset_index(name='image_n')\n",
    "    \n",
    "    return df_imgn\n",
    "\n",
    "def count_cells(df, cols):\n",
    "    '''\n",
    "    takes a df and counts the number of instances each distinct row \n",
    "    (created by unique combinations of labels from columns indicated\n",
    "    by cols arg); counts are reported in a new col called \"cell_counts\"\n",
    "    args:\n",
    "        df: pd.core.frame.DataFrame(N, M); N: the number of rows, M: the\n",
    "            number of cols (assumed to have already been split by stain_type)\n",
    "        cols: list(n), n: the number of cols over which to count distinct rows\n",
    "    return:\n",
    "        df_counts: pd.core.frame.DataFrame(N,M+1)\n",
    "    '''\n",
    "    df_counts = df.value_counts(cols)\\\n",
    "        .reset_index(name='cell_counts')\\\n",
    "        .sort_values(by=cols)\n",
    "    \n",
    "    return df_counts\n",
    "\n",
    "def sum_cells(df, cols, iid_col):\n",
    "    '''\n",
    "    takes cell count df, groups by cols denoted in cols list and computes sum\n",
    "    of cell_counts col for each group. Adds new column \"cell_count_sums\"\n",
    "    containing sums.\n",
    "    args:\n",
    "        df: pd.core.frame.DataFrame(N, M), N: the number of rows (N=|id_col|),\n",
    "            M: the number of cols, must contain col called \"cell_counts\"\n",
    "        cols: list(M-2), list containing col name strings that define each group \n",
    "            for group by and reduction (in this case summing)\n",
    "        iid_col: str, denotes \n",
    "    '''\n",
    "    # remove image id col (we want to sum counts across all images per rat)\n",
    "    reduce_cols = list(filter(lambda x: x != iid_col, cols))\n",
    "\n",
    "    if 'scaled_counts' in df.columns:\n",
    "            # group by, reduce \n",
    "        df_sums = df.groupby(by=reduce_cols)\\\n",
    "            .apply(lambda x: np.sum(x.scaled_counts))\\\n",
    "            .reset_index(name='cell_count_sums')\n",
    "    \n",
    "    else:\n",
    "        # group by, reduce \n",
    "        df_sums = df.groupby(by=reduce_cols)\\\n",
    "            .apply(lambda x: np.sum(x.cell_counts))\\\n",
    "            .reset_index(name='cell_count_sums')\n",
    "    \n",
    "    return df_sums\n",
    "\n",
    "def average_counts(df_sums, df_ns, cols, sid_col, iid_col):\n",
    "    '''\n",
    "    takes df of cell count sums and df of image ns, and computes the mean cell \n",
    "    n (divides cell count sums by the number of images) for each subject.\n",
    "    args:\n",
    "        df_sums: pd.core.frame.DataFrame(ni, mi), ni: the number of rows\n",
    "            (ni=|sid|), mi: the number of cols (mi = |cols|); must \n",
    "            contain a col \"cell_count_sums\". \n",
    "        df_ns: pd.core.frame.DataFrame(nj, mj), nj: the number of rows \n",
    "            (nj=|sid|), mj: the number of cols (mj=2); must contain a col\n",
    "            \"image_n\" \n",
    "        cols: list(n), n: the number of cols (contains all cols necessary to \n",
    "            create every unique group combination)\n",
    "        sid_col: str, denoting the name of the col containing unique subject ids\n",
    "        iid_col: str, denoting the name of the col containing unique image ids\n",
    "    return:\n",
    "        mean_cell_ns: pd.core.frame.DataFrame(N,M), N: the number of rows (N=\n",
    "        |sid|), M: the number of cols (M=|cols|+2)\n",
    "        \n",
    "    '''\n",
    "    # list of cols with out image id, since it was removed during the reduction step\n",
    "    reduce_cols = list(filter(lambda x: x != iid_col, cols))\n",
    "\n",
    "    # compute mean cell n\n",
    "    mean_cell_ns = df_sums.join(df_ns.set_index(sid_col), on=sid_col, how='inner')\\\n",
    "        .sort_values(by=reduce_cols)\n",
    "    mean_cell_ns['mean_cell_n'] = mean_cell_ns.cell_count_sums / mean_cell_ns.image_n\n",
    "\n",
    "    # reorder so that subject id is the first col\n",
    "    col_reorder = [sid_col] + list(filter(lambda x: x != sid_col, list(mean_cell_ns.columns)))\n",
    "    mean_cell_ns = mean_cell_ns[col_reorder]\n",
    "\n",
    "    return mean_cell_ns\n",
    "\n",
    "def mean_cell_n(df_stain, df_full, cols, sid, iid, return_counts=False):\n",
    "    '''\n",
    "    wrapper function to compute mean cell ns; magnification/zoom factor \n",
    "    is assuemd to be equal across all images\n",
    "    args:\n",
    "        df_stain: pd.core.frame.DataFrame; df containing data for a given stain type\n",
    "        df_full: pd.core.frame.DataFrame; df containing data for full (cleaned) set\n",
    "        cols: list, contains str denoting col names for grouping\n",
    "        sid: str, col name denoting col containing unique subject ids\n",
    "        iid: str, col name denoting col containing unique image ids\n",
    "        return_counts: bool, flag for added utility during debugging\n",
    "    '''\n",
    "    # count n of unique image names per subject\n",
    "    img_ns = count_imgs(df_full, sid, iid)\n",
    "\n",
    "    # count n of cells per image for each subject\n",
    "    cell_counts = count_cells(df_stain, cols)\n",
    "\n",
    "    # sum cell counts across all images for each subject\n",
    "    cell_sums = sum_cells(cell_counts, cols, iid)\n",
    "\n",
    "    # compute mean cell count per image for each subject\n",
    "    mean_cell_ns = average_counts(cell_sums, img_ns, cols, sid, iid)\n",
    "\n",
    "    if not return_counts:\n",
    "        return mean_cell_ns\n",
    "    \n",
    "    return (cell_counts, mean_cell_ns)\n",
    "\n",
    "\n",
    "def scaled_mean_cell_n(df_stain, df_full, cols, sid, iid, return_counts=False, scale_counts=False):\n",
    "    '''\n",
    "    wrapper function to compute mean cell ns for images of unequal zoom factor\n",
    "    args:\n",
    "        df_stain: pd.core.frame.DataFrame; df containing data for a given stain type\n",
    "        df_full: pd.core.frame.DataFrame; df containing data for full (cleaned) set\n",
    "        cols: list, contains str denoting col names for grouping\n",
    "        sid: str, col name denoting col containing unique subject ids\n",
    "        iid: str, col name denoting col containing unique image ids\n",
    "        return_counts: bool, flag for added utility during debugging\n",
    "    '''\n",
    "    # count n of unique image names per subject\n",
    "    img_ns = count_imgs(df_full, sid, iid)\n",
    "\n",
    "    # count n of cells per image for each subject\n",
    "    cell_counts = count_cells(df_stain, cols)\n",
    "\n",
    "    # we must scale at the cell count per image level because it may be the case that\n",
    "    # not every image from a given animal was scaled the same way\n",
    "    if scale_counts:\n",
    "        # get magnification_factor for each img\n",
    "        mag = df_full[[sid, iid, 'magnification_factor']].drop_duplicates()\n",
    "        cell_counts = cell_counts.merge(mag)\n",
    "\n",
    "        # scale all counts by max magnification factor\n",
    "        max_mag = cell_counts.magnification_factor.unique().max()\n",
    "        cell_counts['scale'] = cell_counts.magnification_factor / max_mag\n",
    "        cell_counts['scaled_counts'] = cell_counts.cell_counts * cell_counts.scale\n",
    "\n",
    "    # sum cell counts across all images for each subject\n",
    "    cell_sums = sum_cells(cell_counts, cols, iid)\n",
    "\n",
    "    # compute mean cell count per image for each subject\n",
    "    mean_cell_ns = average_counts(cell_sums, img_ns, cols, sid, iid)\n",
    "\n",
    "    if not return_counts:\n",
    "        return mean_cell_ns\n",
    "    \n",
    "    return cell_counts, mean_cell_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to run it! Write to disk and check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double-labeled_WFA_co-occurring_with_PV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_number</th>\n",
       "      <th>sex</th>\n",
       "      <th>treatment</th>\n",
       "      <th>ZT</th>\n",
       "      <th>cell_count_sums</th>\n",
       "      <th>image_n</th>\n",
       "      <th>mean_cell_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF018</td>\n",
       "      <td>F</td>\n",
       "      <td>SD</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF020</td>\n",
       "      <td>F</td>\n",
       "      <td>SD</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>6</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF050</td>\n",
       "      <td>F</td>\n",
       "      <td>SD</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6</td>\n",
       "      <td>25.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF052</td>\n",
       "      <td>F</td>\n",
       "      <td>SD</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF026</td>\n",
       "      <td>F</td>\n",
       "      <td>SD</td>\n",
       "      <td>3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>RM070</td>\n",
       "      <td>M</td>\n",
       "      <td>ZT0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>6</td>\n",
       "      <td>27.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>RM073</td>\n",
       "      <td>M</td>\n",
       "      <td>ZT0</td>\n",
       "      <td>0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>RM078</td>\n",
       "      <td>M</td>\n",
       "      <td>ZT0</td>\n",
       "      <td>0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>RM081</td>\n",
       "      <td>M</td>\n",
       "      <td>ZT0</td>\n",
       "      <td>0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>RM084</td>\n",
       "      <td>M</td>\n",
       "      <td>ZT0</td>\n",
       "      <td>0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>6</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_number sex treatment  ZT  cell_count_sums  image_n  mean_cell_n\n",
       "0            RF018   F        SD   0            128.0        6    21.333333\n",
       "1            RF020   F        SD   0            129.0        6    21.500000\n",
       "2            RF050   F        SD   0            151.0        6    25.166667\n",
       "3            RF052   F        SD   0             28.0        6     4.666667\n",
       "4            RF026   F        SD   3             72.0        6    12.000000\n",
       "..             ...  ..       ...  ..              ...      ...          ...\n",
       "143          RM070   M       ZT0   0            163.0        6    27.166667\n",
       "144          RM073   M       ZT0   0            142.0        6    23.666667\n",
       "145          RM078   M       ZT0   0            114.0        6    19.000000\n",
       "146          RM081   M       ZT0   0            142.0        6    23.666667\n",
       "147          RM084   M       ZT0   0            117.0        6    19.500000\n",
       "\n",
       "[148 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up\n",
    "group = 'SD_fulldb' # identifying str for writing files to disk\n",
    "sid = 'subject_number'\n",
    "iid = 'image_name'\n",
    "cols = ['sex', 'treatment', 'ZT', 'subject_number', 'image_name']\n",
    "\n",
    "# time to count\n",
    "for stain in df_clean.stain_type.unique():\n",
    "    # split by stain type\n",
    "    df_stain = df_clean[df_clean.stain_type == stain]\n",
    "\n",
    "    # compute mean count\n",
    "    df_means = scaled_mean_cell_n(df_stain, df_clean, cols, sid, iid, scale_counts=True)\n",
    "\n",
    "    # write result to disk\n",
    "    df_means.to_csv(f'{group}_{stain}_SCALED_mean_cell_ns.csv')\n",
    "\n",
    "# let's take a look at one of our final output dataframes\n",
    "# we know if an image was scaled if \"cell_count_sums\" is not an integer\n",
    "# (we expect sums of count data to be int)\n",
    "print(stain)\n",
    "df_means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
